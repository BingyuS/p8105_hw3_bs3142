p8105\_hw3\_bs3142
================
Bingyu Sun
10/7/2018

Problem 1
---------

#### Section 1: Data import

``` r
library(p8105.datasets)
data(brfss_smart2010)
```

#### Section 2: Data Manipulation

``` r
brfss_data =
  brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic == "Overall Health") %>%
  select(-(class:question), -sample_size, -(confidence_limit_low:geo_location)) %>%
  mutate(response = factor(response, levels = c("Excellent", "Very good", "Good", "Fair", "Poor")))

str(brfss_data)
```

    ## Classes 'tbl_df', 'tbl' and 'data.frame':    10625 obs. of  5 variables:
    ##  $ year        : int  2010 2010 2010 2010 2010 2010 2010 2010 2010 2010 ...
    ##  $ locationabbr: chr  "AL" "AL" "AL" "AL" ...
    ##  $ locationdesc: chr  "AL - Jefferson County" "AL - Jefferson County" "AL - Jefferson County" "AL - Jefferson County" ...
    ##  $ response    : Factor w/ 5 levels "Excellent","Very good",..: 1 2 3 4 5 1 2 3 4 5 ...
    ##  $ data_value  : num  18.9 30 33.1 12.5 5.5 15.6 31.3 31.2 15.5 6.4 ...

#### Section 3: Q & A

**1. In 2002, which states were observed at 7 locations?**

``` r
brfss_data %>%
  filter(year == 2002) %>%
  group_by(locationabbr) %>%
  summarize(n_obs = n_distinct(locationdesc))
```

    ## # A tibble: 49 x 2
    ##    locationabbr n_obs
    ##    <chr>        <int>
    ##  1 AK               1
    ##  2 AL               1
    ##  3 AR               1
    ##  4 AZ               2
    ##  5 CA               1
    ##  6 CO               4
    ##  7 CT               7
    ##  8 DC               1
    ##  9 DE               3
    ## 10 FL               7
    ## # ... with 39 more rows

**CT, FL, NC** were observed at 7 locations.

**2. Make a “spaghetti plot” that shows the number of observations in each state from 2002 to 2010.**

``` r
brfss_data %>%
  group_by(year, locationabbr) %>%
  summarize(n_obs = n_distinct(locationdesc)) %>%
  ggplot(aes(x = year, y = n_obs, color = locationabbr)) + 
    geom_line() +
    labs(
      title = "Number of observations in each state 2002-2010",
      x = "Year",
      y = "Number of observations",
      caption = "Data from brfss_smart2010"
  ) +
  viridis::scale_color_viridis(
    name = "State", 
    discrete = TRUE
  )
```

<img src="p8105_hw3_bs3142_files/figure-markdown_github/unnamed-chunk-3-1.png" width="90%" />

**3. Make a table showing, for the years 2002, 2006, and 2010, the mean and standard deviation of the proportion of “Excellent” responses across locations in NY State.**

``` r
brfss_data %>%
  filter(year %in% c("2002", "2006", "2010"), response == "Excellent", locationabbr == "NY") %>%
  spread(key = response, value = data_value) %>%
  group_by(year) %>%
  summarize(
    mean_prop_excellent_NY = mean(Excellent, na.rm = TRUE),
    sd_prop_excellent_NY = sd(Excellent, na.rm = TRUE)
  ) %>%
  knitr::kable(digits = 1)
```

|  year|  mean\_prop\_excellent\_NY|  sd\_prop\_excellent\_NY|
|-----:|--------------------------:|------------------------:|
|  2002|                       24.0|                      4.5|
|  2006|                       22.5|                      4.0|
|  2010|                       22.7|                      3.6|

**4. For each year and state, compute the average proportion in each response category (taking the average across locations in a state). Make a five-panel plot that shows, for each response category separately, the distribution of these state-level averages over time.**

``` r
brfss_data %>%
  group_by(year, locationabbr, response) %>%
  summarize(mean_prop_response = mean(data_value))
```

    ## # A tibble: 2,215 x 4
    ## # Groups:   year, locationabbr [?]
    ##     year locationabbr response  mean_prop_response
    ##    <int> <chr>        <fct>                  <dbl>
    ##  1  2002 AK           Excellent               27.9
    ##  2  2002 AK           Very good               33.7
    ##  3  2002 AK           Good                    23.8
    ##  4  2002 AK           Fair                     8.6
    ##  5  2002 AK           Poor                     5.9
    ##  6  2002 AL           Excellent               18.5
    ##  7  2002 AL           Very good               30.9
    ##  8  2002 AL           Good                    32.7
    ##  9  2002 AL           Fair                    12.1
    ## 10  2002 AL           Poor                     5.9
    ## # ... with 2,205 more rows

????????

Problem 2
---------

#### Section 1: Data import

``` r
data(instacart)
```

#### Section 2: Data exploration

**Summary**

#### Section 3: Q & A

**1. How many aisles are there, and which aisles are the most items ordered from?**

``` r
instacart %>%
  summarize(
    n_aisle = n_distinct(aisle),
    max_items = max(add_to_cart_order))
```

    ## # A tibble: 1 x 2
    ##   n_aisle max_items
    ##     <int>     <dbl>
    ## 1     134        80

There are **134** aisles. **nuts seeds dried fruit** and **packaged vegetables fruits** Which aisles are the most items ordered from?????

**2. Make a plot that shows the number of items ordered in each aisle. Order aisles sensibly, and organize your plot so others can read it.**

``` r
instacart %>%
  distinct(aisle, add_to_cart_order)
```

    ## # A tibble: 6,869 x 2
    ##    add_to_cart_order aisle                        
    ##                <int> <chr>                        
    ##  1                 1 yogurt                       
    ##  2                 2 other creams cheeses         
    ##  3                 3 fresh vegetables             
    ##  4                 4 fresh vegetables             
    ##  5                 5 canned meat seafood          
    ##  6                 6 fresh fruits                 
    ##  7                 7 fresh fruits                 
    ##  8                 8 packaged cheese              
    ##  9                 1 specialty cheeses            
    ## 10                 2 water seltzer sparkling water
    ## # ... with 6,859 more rows

?????????

**3. Make a table showing the most popular item aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”.**

``` r
instacart %>%
  select(aisle, add_to_cart_order, product_name) %>%
  filter(aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle, product_name) %>%
  summarize(most_popular_item = max(add_to_cart_order))
```

    ## # A tibble: 1,114 x 3
    ## # Groups:   aisle [?]
    ##    aisle           product_name                           most_popular_it…
    ##    <chr>           <chr>                                             <dbl>
    ##  1 baking ingredi… 1 to 1 Gluten Free Baking Flour                      29
    ##  2 baking ingredi… 1-to-1 Baking Flour, Gluten/Wheat/Dai…               22
    ##  3 baking ingredi… 100% Cacao Unsweetened Chocolate Baki…               15
    ##  4 baking ingredi… 100% Natural Sweetener Zero Calorie P…               33
    ##  5 baking ingredi… 100% Natural Zero Calorie Sweetener                   9
    ##  6 baking ingredi… 100% Organic Einkorn  All-Purpose Flo…               11
    ##  7 baking ingredi… 100% Organic Premium Whole Wheat Flour               20
    ##  8 baking ingredi… 100% Organic Unbleached All-Purpose F…               36
    ##  9 baking ingredi… 100% Organic Unbleached White Whole W…               21
    ## 10 baking ingredi… 100% Pure Corn Starch                                29
    ## # ... with 1,104 more rows

????????????

**4. Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).**

``` r
instacart %>%
  filter(product_name == c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  select(product_name, order_hour_of_day) %>%
  group_by(product_name) %>%
  summarize(mean_hour_of_day = mean(order_hour_of_day))
```

    ## Warning in product_name == c("Pink Lady Apples", "Coffee Ice Cream"):
    ## longer object length is not a multiple of shorter object length

    ## # A tibble: 2 x 2
    ##   product_name     mean_hour_of_day
    ##   <chr>                       <dbl>
    ## 1 Coffee Ice Cream             13.7
    ## 2 Pink Lady Apples             12.5

??? how to add week???
